dataloader_args:
  batch_size: 2 #RTX2080 1, V100: 8, A800: 16
  drop_last: true
  num_workers: 12
  pin_memory: true
  prefetch_factor: 6

dataset_args:
  resample_rate: &sr 16000
  sample_num_per_epoch: 0
  shuffle: False
  shuffle_args:
    shuffle_size: 2500
  whole_utt: True
  chunk_len: 48000
  noise_prob: 0 # noqa
  noise_lmdb_file: './data/musan/lmdb'
  mc_target: True
  cues:
    spatial:
      use: true
      required: true
  cue_processing:
    spatial:

enable_amp: True
exp_dir: exp/tse_nbc2_spatial_doaemb
gpus: '0,1'
log_batch_interval: 100

loss: SISDR
loss_args: { }
whole_utt: True
# loss: [SISDR, CE]               ### For joint training the speaker encoder with CE loss. Put SISDR in the first position for validation set
# loss_args:
#   loss_posi: [[0],[1]]
#   loss_weight: [[1.0],[1.0]]

model:
  tse_model: TSE_NBC2_SPATIAL
model_args:
  tse_model:
    win: 512         
    stride: 256      
    separator:
      n_layers: 8          
      dim_hidden: 96       
      dim_ffn: 192        
      block_kwargs:
        n_heads: 2
        dropout: 0.1
        conv_kernel_size: 3
        n_conv_groups: 8
    spatial:
      geometry:
        fs: 16000
        c: 343.0
        mic_spacing: 0.03333333 

      pairs:
        - [0, 1]
        - [1, 2]
        - [2, 3]
        - [0, 3]
      mic_coords:
        - [-0.05,        0.0, 0.0]  # Mic 0 (最左)
        - [-0.0166,  0.0, 0.0]  # Mic 1
        - [ 0.0166,  0.0, 0.0]  # Mic 2
        - [ 0.05,        0.0, 0.0]  # Mic 3 (最右)
      features:
        ipd: 
          enabled: True        
        cdf: 
          enabled: False       
        sdf: 
          enabled: False        
        delta_stft: 
          enabled: True
        cyc_doaemb:
          enabled: True
          cyc_alpha: 20
          cyc_dimension: 40
          use_ele: True
          out_channel: 1          
          fusion: concat

# find_unused_parameters: True

model_init:
  tse_model: null
  discriminator: null
  spk_model: null

num_avg: 10
num_epochs: 150

optimizer:
  tse_model: Adam
optimizer_args:
  tse_model:
    lr: 0.001  # NOTICE: These args do NOT work! The initial lr is determined in the scheduler_args currently!
    weight_decay: 0.0001

clip_grad: 5.0
save_epoch_interval: 1

scheduler:
  tse_model: ExponentialDecrease
scheduler_args:
  tse_model:
    final_lr: 2.5e-05
    initial_lr: 0.001
    warm_from_zero: false
    warm_up_epoch: 0

seed: 42
